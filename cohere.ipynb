{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "API_KEY = \"d3po2kzyu6VFsZPP1VFc0h79rYhDBf5hVoT9EnNL\"\n",
    "co = cohere.Client(API_KEY)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent Recognition\n",
    "This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cohere.classify import Example\n",
    "\"\"\"\n",
    "These are the training examples we give the model to show the classes we \n",
    "want it to classify. Each example contains the text itself and the corresponding label,\n",
    " or class. The minimum number of examples required is five per class.\n",
    "\n",
    "\"\"\"\n",
    "examples =  [\n",
    "  Example(\"Do you offer same day shipping?\", \"Shipping and handling policy\"),  \n",
    "  Example(\"Can you ship to Italy?\", \"Shipping and handling policy\"),  \n",
    "    Example(\"How long does shipping take?\", \"Shipping and handling policy\"),  \n",
    "    Example(\"Can I buy online and pick up in store?\", \"Shipping and handling policy\"),  \n",
    "    Example(\"What are your shipping options?\", \"Shipping and handling policy\"),  \n",
    "    Example(\"My order arrived damaged, can I get a refund?\", \"Start return or exchange\"),  \n",
    "    Example(\"You sent me the wrong item\", \"Start return or exchange\"),  \n",
    "    Example(\"I want to exchange my item for another colour\", \"Start return or exchange\"),  \n",
    "    Example(\"I ordered something and it wasn't what I expected. Can I return it?\", \"Start return or exchange\"),  \n",
    "    Example(\"What's your return policy?\", \"Start return or exchange\"),  \n",
    "    Example(\"Where's my package?\", \"Track order\"),  \n",
    "    Example(\"When will my order arrive?\", \"Track order\"),  \n",
    "    Example(\"What's my shipping number?\", \"Track order\"),  \n",
    "    Example(\"Which carrier is my package with?\", \"Track order\"),  \n",
    "    Example(\"Is my package delayed?\", \"Track order\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification<prediction: \"Start return or exchange\", confidence: 0.99227476>\n",
      "Classification<prediction: \"Track order\", confidence: 0.9956143>\n",
      "Classification<prediction: \"Shipping and handling policy\", confidence: 0.9996762>\n"
     ]
    }
   ],
   "source": [
    "inputs=[\" Am I still able to return my order?\",  \n",
    "        \"When can I expect my package?\",  \n",
    "        \"Do you ship overseas?\",  \n",
    "        ]\n",
    "\n",
    "response = co.classify(  \n",
    "    model='medium',  \n",
    "    inputs=inputs,  \n",
    "    examples=examples)\n",
    "\n",
    "for x in response.classifications:\n",
    "  print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization\n",
    "The goal of text summarization is to condense the original text into a shorter version that retains the most important information. In this example, we want to summarize a passage from a news article into its main point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Passage: Is Wordle getting tougher to solve? Players seem to be convinced that the game has gotten harder in recent weeks ever since The New York Times bought it from developer Josh Wardle in late January. The Times has come forward and shared that this likely isn't the case. That said, the NYT did mess with the back end code a bit, removing some offensive and sexual language, as well as some obscure words There is a viral thread claiming that a confirmation bias was at play. One Twitter user went so far as to claim the game has gone to \"the dusty section of the dictionary\" to find its latest words.\n",
    "\n",
    "TLDR: Wordle has not gotten more difficult to solve.\n",
    "--\n",
    "Passage: ArtificialIvan, a seven-year-old, London-based payment and expense management software company, has raised $190 million in Series C funding led by ARG Global, with participation from D9 Capital Group and Boulder Capital. Earlier backers also joined the round, including Hilton Group, Roxanne Capital, Paved Roads Ventures, Brook Partners, and Plato Capital.\n",
    "\n",
    "TLDR: ArtificialIvan has raised $190 million in Series C funding.\n",
    "--\n",
    "Passage: The National Weather Service announced Tuesday that a freeze warning is in effect for the Bay Area, with freezing temperatures expected in these areas overnight. Temperatures could fall into the mid-20s to low 30s in some areas. In anticipation of the hard freeze, the weather service warns people to take action now.\n",
    "\n",
    "TLDR:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There's a freeze warning in effect for the Bay Area.\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "response = co.generate( \n",
    "    model='xlarge', \n",
    "    prompt = prompt,\n",
    "    max_tokens=40, \n",
    "    temperature=0.8,\n",
    "    stop_sequences=[\"--\"])\n",
    "\n",
    "summary = response.generations[0].text\n",
    "print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cohere.classify import Example\n",
    "\n",
    "examples=[\n",
    "  Example(\"The order came 5 days early\", \"positive\"), \n",
    "  Example(\"The item exceeded my expectations\", \"positive\"), \n",
    "  Example(\"I ordered more for my friends\", \"positive\"), \n",
    "  Example(\"I would buy this again\", \"positive\"), \n",
    "  Example(\"I would recommend this to others\", \"positive\"), \n",
    "  Example(\"The package was damaged\", \"negative\"), \n",
    "  Example(\"The order is 5 days late\", \"negative\"), \n",
    "  Example(\"The order was incorrect\", \"negative\"), \n",
    "  Example(\"I want to return my item\", \"negative\"), \n",
    "  Example(\"The item\\'s material feels low quality\", \"negative\"), \n",
    "  Example(\"The product was okay\", \"neutral\"), \n",
    "  Example(\"I received five items in total\", \"neutral\"), \n",
    "  Example(\"I bought it from the website\", \"neutral\"), \n",
    "  Example(\"I used the product this morning\", \"neutral\"), \n",
    "  Example(\"The product arrived yesterday\", \"neutral\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification<prediction: \"negative\", confidence: 0.98533106>\n",
      "Classification<prediction: \"neutral\", confidence: 0.8999864>\n",
      "Classification<prediction: \"neutral\", confidence: 0.99774724>\n"
     ]
    }
   ],
   "source": [
    "inputs=[\n",
    "  \"This item was broken when it arrived\",\n",
    "  \"The product is amazing\",\n",
    "  \"The product was not too bad\",\n",
    "]\n",
    "response = co.classify(\n",
    "  model='medium',\n",
    "  inputs=inputs,\n",
    "  examples=examples,\n",
    ")\n",
    "\n",
    "for x in response.classifications:\n",
    "    print(x) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co.Generate\n",
    "This endpoint generates realistic text conditioned on a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"  \n",
    "This program generates a startup idea and name given the industry.\n",
    "\n",
    "Industry: Workplace  \n",
    "Startup Idea: A platform that generates slide deck contents automatically based on a given outline  \n",
    "Startup Name: Deckerize  \n",
    "--  \n",
    "Industry: Home Decor  \n",
    "Startup Idea: An app that calculates the best position of your indoor plants for your apartment  \n",
    "Startup Name: Planteasy\n",
    "--  \n",
    "Industry: Healthcare  \n",
    "Startup Idea: A hearing aid for the elderly that automatically adjusts its levels and with a battery lasting a whole week  \n",
    "Startup Name: Hearspan\n",
    "\n",
    "--  \n",
    "Industry: Education  \n",
    "Startup Idea: An online school that lets students mix and match their own curriculum based on their interests and goals  \n",
    "Startup Name: Prime Age\n",
    "\n",
    "--  \n",
    "Industry: Productivity  \n",
    "Startup Idea:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A service that turns all your business expenses into a credit card that you can use to pay them off  \n",
      "Startup Name: Expense Manager\n",
      "\n",
      "# Chapter 3. Mastering Data Science\n"
     ]
    }
   ],
   "source": [
    "response = co.generate(  \n",
    "    model='xlarge',  \n",
    "    prompt = prompt,  \n",
    "    max_tokens=40,  \n",
    "    temperature=0.6,  \n",
    "    stop_sequences=[\"--\"])\n",
    "\n",
    "startup_idea = response.generations[0].text\n",
    "print(startup_idea)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c39067fb85dad44b96a991ff273746e02ffde2a07ab0e300120c2298a074d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
